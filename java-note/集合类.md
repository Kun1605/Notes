# 集合类 #

* [1、Collection接口](#1、Collection接口)
* [2、List接口](#2、List接口)
* [3、Map接口](#3、Map接口)
* [4、Set接口](#4、Set接口)
* [5、总结](#5、总结)
* [6、集合中的概念](#6、集合中的概念)
* [7、queue接口](#7、queue接口)

<a name="1、Collection接口"></a>
### 1、Collection接口 ###

	Collection是最基本的集合接口，一个Collection代表一组Object，即Collection的元素（Elements）。

	所有实现Collection接口的类都必须提供两个标准的构造函数：
		1. 无参数的构造函数：用于创建一个空的Collection；
		2. 有一个 Collection参数的构造函数：用于创建一个新的Collection，这个新的Collection与传入的Collection有相同的元素。
		后一个构造函数允许用户复制一个Collection。

	Collections 是一个集合的静态方法工具类，提供了操作集合的各种方法。具体方法参考API。

> 遍历Collection中的每一个元素

	不论Collection的实际类型如何，它都支持一个iterator()的方法。
	该方法返回一个迭代器，使用该迭代器即可遍历访问Collection中每一个元素，通过Iterator的遍历是无序的。

> 典型的用法如下：
	
	Iterator it = collection.iterator(); // 获得一个迭代
	while(it.hasNext()) {
	     Object obj = it.next(); // 得到下一个元素
	}
	
> Iterator和ListIterator的区别
	
	Iterator可用来遍历Set和List集合，但是ListIterator只能用来遍历List。
	Iterator对集合只能是前向遍历，ListIterator既可以前向也可以后向。
	ListIterator实现了Iterator接口，并包含其他的功能，比如：增加元素，替换元素，获取前一个和后一个元素的索引。

<a name="2、List接口"></a>
### 2、List接口 ###

- List是有序的Collection，使用此接口能够精确的控制每个元素插入的位置。用户能够使用索引（元素在List中的位置，类似于数组下标）来访问List中的元素，这类似于Java的数组。
- 除了具有Collection接口必备的iterator()方法外，List还提供一个listIterator()方法，返回一个 ListIterator接口，和标准的Iterator接口相比，ListIterator多了一些add()之类的方法，允许添加，删除，设定元素，还能向前或向后遍历。
- 实现List接口的常用类有LinkedList，ArrayList，Vector和Stack。
 
> LinkedList类

	LinkedList基于链表的数据结构。
	LinkedList实现了List接口，允许null元素。此外LinkedList提供额外的get，remove，insert方法。
	这些操作使LinkedList可被用作堆栈（stack），队列（queue）或双向队列（deque）。
	注意，LinkedList 没有同步性。
	如果多个线程同时访问一个LinkedList，则必须自己实现访问同步。
	解决方法是在创建List时构造一个同步的List：List list = Collections.synchronizedList(new LinkedList(...));
 

> ArrayList类

	ArrayList实现了大小可变的数组，是基于动态数组的数据结构。它允许所有元素，包括null。
	默认创建了大小为 10 的数组。
	ArrayList没有同步性，线程非安全。
	size，isEmpty，get，set方法运行时间为常数。但是add方法开销为分摊的常数，添加n个元素需要O(n)的时间。其他的方法运行时间为线性。
	每个ArrayList实例都有一个容量（Capacity），即用于存储元素的数组的大小。这个容量可随着不断添加新元素而自动增加，但是增长算法并没有定义。
	当需要插入大量元素时，在插入前可以调用ensureCapacity方法来增加ArrayList的容量以提高插入效率。
 

> Vector【向量】类

	Vector非常类似ArrayList，但是Vector是同步的。
	由Vector创建的Iterator，虽然和 ArrayList创建的Iterator是同一接口，但是Vector是同步的。
	当一个Iterator被创建而且正在被使用，另一个线程改变了 Vector的状态（例如，添加或删除了一些元素），这时调用Iterator的方法时将抛出 ConcurrentModificationException，因此必须捕获该异常。  

> Stack 类
	
	Stack继承自Vector，实现一个后进先出的堆栈。
	Stack提供5个额外的方法使得Vector得以被当作堆栈使用。
	基本的 push 和 pop 方法，还有 peek 方法得到栈顶的元素，empty方法测试堆栈是否为空，search方法检测一个元素在堆栈中的位置。
	Stack刚创建后是空栈。

> Vector、ArrayList和LinkedList比较

	1. Vector是线程同步的，所以它也是线程安全的，而ArrayList和LinkedList是非线程安全的。如果不考虑到线程的安全因素，一般用ArrayList和LinkedList效率比较高。

	2. ArrayList和Vector是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。

	3. 如果集合中的元素的数目大于目前集合数组的长度时，Vector增长率为目前数组长度的100%，而ArrayList增长率为目前数组长度的50%。
		如果在集合中使用数据量比较大的数据，用vector有一定的优势；反之，用ArrayList有优势。

	4. 如果查找一个指定位置的数据，Vector和ArrayList使用的时间是相同的，花费时间为O(1)，直接通过下标就定位到了数据，而LinkedList需要遍历查找，花费时间为O(n)，效率不如前两者。

	5. 如果移动、删除一个指定位置的数据，ArrayList 花费的时间为O(n-i)【n为总长度】，这个时候就应该考虑使用LinkedList，因为它移动一个指定位置的数据所花费的时间为0(1)。

	6. 对于在指定位置插入、删除数据，LinedList比较占优势，不用移动数据，而ArrayList要对数据进行移位操作，消耗时间大。
 
> 排序

	实现 Comparable<T> 接口，然后重写里面的 compareTo()方法。

	重写的 public int compareTo(Object o){} 这个方法，它返回三种 int 类型的值： 负整数，零 ，正整数。

		返回值		含义
		负整数		当前对象的值 < 比较对象的值 ， 位置排在前
		零		    当前对象的值 = 比较对象的值 ， 位置不变
		正整数		当前对象的值 > 比较对象的值 ， 位置排在后

	当前值 - 比较值，返回正整数即表示当前值大于比较值。

	索引1 减 索引2 ，用大的和小的比较，即从小到大，升序；
	索引2 减 索引1 ，用小的和大的比较，即从大到小，降序。

	Comparator 的使用有两种方式：

		1. Collections.sort(list,Comparator<T>）;
		2. list.sort(Comparator<T>);

	Comparator 中的 compare(当前值，比较值) 方法和 Comparable<> 接口中的 compareTo(Object o) 方法 返回值意思相同。

	其实主要是看 Comparator 接口的实现，重写里面的 compare 方法。

		Collections.sort(list, new Comparator<Student>() {
		    @Override
		    public int compare(Student o1, Student o2) {
				//从小到大，升序
		        return o1.getId() - o2.getId();
				
				//从大到小，降序
		        return o2.getId() - o1.getId();
		    }
		});

		//从小到大，升序
		list.sort(new Comparator<Student>() {
		    @Override
		    public int compare(Student o1, Student o2) {
		        return o1.getId() - o2.getId();
		    }
		});

		使用 Comparator 的静态方法 comparingInt
		可以简化为
		list.sort(Comparator.comparingInt(Student::getId));


<a name="3、Map接口"></a>
### 3、Map接口 ###

- 请注意，Map 没有继承 Collection 接口，Map提供key到value的映射。
- 一个Map中**不能包含相同的key**，每个key只能映射一个 value。
- Map接口提供3种集合的视图，Map的内容可以被当作一组key集合，一组value集合，或者一组key-value映射。  

> Hashtable类

	Hashtable 继承 Map 接口，实现一个key-value映射的哈希表。
	Entry数组 + 链表的形式实现。
	任何非空（non-null）的对象都可作为key或者value。
	添加数据使用put(key, value)，取出数据使用get(key)，这两个基本操作的时间开销为常数。

	Hashtable是线程安全的，同步的，相当于 hashmap + synchronized【全方法加锁】。
	但是HashTable线程安全的策略实现代价却太大了，get/put所有相关操作都是synchronized的，这相当于给整个哈希表加了一把大锁。
	多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞，相当于将所有的操作串行化，在竞争激烈的并发场景中性能就会非常差。

	初始 Capacity为 11
	扩容：int newCapacity = (oldCapacity << 1) + 1【即2次幂扩展 +1。】 ，加载因子：0.75

	计算index的方法：
		Entry<?,?> tab[] = table;
		int hash = key.hashCode();
		int index = (hash & 0x7FFFFFFF) % tab.length;	

	哈希值和16进制的最大值进行与运算后再对表的长度做取余运算。

	0x7FFFFFFF：16进制的最大值

> HashMap类

	HashMap 和 Hashtable类似，不同之处在于HashMap是非同步的，线程不安全的，并且允许null 键和null 值。
	
	HashMap 由 Entry数组 + 链表 组成的，Entry数组是HashMap的主体，链表也是Entry【静态内部类】形式。
	JDK1.8后变成 Entry数组 + 链表 + 红黑树 结构。
	Entry是HashMap的基本组成单元，每一个Entry包含一个key/value键值对。

	链表则是主要为了解决哈希冲突而存在的【由于不同的key有可能对象相同的hash值，此时根据哈希值计算得到的存放数组的下标就冲突了，所以把数组中同一个下标的不同数值以链表结构存放】。

	HashMap 的数据是无序的。

	初始容量为16，扩容：newsize = oldsize*2，即2次幂扩展。
	加载因子：0.75，即当Map中元素总数超过Entry数组的75%，触发扩容操作。

	扩容针对整个Map，每次扩容时，原来数组中的元素依次重新计算存放位置，并重新插入【每个索引的元素必须保持相同的索引，或者在新表中以2的偏移量移动】。
	
	resize扩容时，拷贝旧的数据元素，重新新建一个更大容量的空间，然后进行数据复制。
	将数据复制到新数组时，如果链表还在原来索引位置上，则是倒置插入索引位置的【引发线程安全问题】。

	【注】在并发环境下【resize扩容时】可能会形成环状链表，导致get操作时，CPU满负载。
	在扩容时，多个线程都在复制数据，在原来的索引上，链表是倒置插入的。
	链表数据 A-B，线程1 和线程2 同时复制数据，线程1由于时间片用完暂停了，线程2已将链表数据复制完毕，此时链表为 B-A。
	线程1获得时间片后开始执行之前的数据复制，将数据A 插入表头，接着处理数据B，原本B 的后面是null,但是由于 线程2已将数据复制，此时B 的后面指向了A，所以线程1 就继续处理A，将A插入表头，而A又指向B，继续处理B，从而形成了 A-B-A的环形链表。

	计算index方法：
		hash = (h = key.hashCode()) ^ (h >>> 16)	//将hashCode的高16位与hashCode进行异或运算，重新计算hash值
		index = hash & (tab.length – 1)
	
	获取值
		tab[index]

	HashMap的时间复杂度为O（1）。
	
	HashMap的工作原理:

		Java中的 HashMap 是以键值对(key-value)的形式存储元素的。
		HashMap 需要使用 hashCode()和equals() 方法确定键值对的索引【hash值】，从而来向集合添加元素和从集合检索元素。
		通过 hash 值确定索引，通过 key确定是否为同一元素。
		当调用put()方法的时候，HashMap会计算key的hash值，然后把键值对存储在集合中合适的索引上。
			1. 如果索引已经存在则新添Entry节点添加到该索引的链表末尾；
			2. 如果key已经存在了，value会被替换成新值，并将旧值返回；
			3. 如果链表大小超过阈值（TREEIFY_THRESHOLD,8），链表就会被改造为树形结构。

	如果使用实例对象作为 key，则需要重写 hashCode()和equals()，来重新判断 HashMap 中存放的key的唯一性。
	可以把hash表看作是一个数组，通过key的哈希算法算出数组中的下标【hash值】，然后 get(key)/put(key,value) 方法通过索引获取数据。

	当调用 put(key,value) 方法的时候，首先会把 key、value 封装到 Entry 这个静态内部类对象中，把 Entry 再添加到数组中。
	想获取Map中的所有键值对，我们只要获取数组中的所有 Entry对象，然后调用Entry对象中的 getKey 和 getValue 方法就可以获取键值对。 
	Set<Map.Entry<K,V>> entrys = map.entrySet() 

[HashMap详解](https://blog.csdn.net/v123411739/article/details/78996181 "HashMap详解")

> get()方法源码

	public V get(Object key) {
        Node<K,V> e;	
        return (e = getNode(hash(key), key)) == null ? null : e.value;
    }

    final Node<K,V> getNode(int hash, Object key) {
        Node<K,V>[] tab; Node<K,V> first, e; int n; K k;

		// table不为空 && table长度大于0 && table索引位置(根据hash值计算出)不为空
        if ((tab = table) != null && (n = tab.length) > 0 &&
            (first = tab[(n - 1) & hash]) != null) {

			// 总是先检查第一个对象，若first的key等于传入的key则返回first对象
            if (first.hash == hash && 
                ((k = first.key) == key || (key != null && key.equals(k))))
                return first;

			// 如果不是就向下遍历
            if ((e = first.next) != null) {

				// 判断是否为TreeNode，如果是，则调用红黑树的查找目标节点方法getTreeNode
                if (first instanceof TreeNode)
                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);

				// 否则为链表节点，则向下遍历链表，直至找到节点的key和传入的key相等时，返回该节点
                do {
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        return e;
                } while ((e = e.next) != null);
            }
        }
        return null;
    }

	【说明】
		1. 先对table进行校验，校验是否为空，length是否大于0
		2. 使用table.length - 1和hash值进行位与运算，得出在table上的索引位置，将该索引位置的节点赋值给first节点，校验该索引位置是否为空
		3. 检查first节点的hash值和key是否和入参的一样，如果一样则first即为目标节点，直接返回first节点
		4. 如果first的next节点不为空则继续遍历
		5. 如果first节点为TreeNode，则调用getTreeNode方法查找目标节点
		6. 如果first节点不为TreeNode即为普通链表，则调用普通的遍历链表方法查找目标节点
		7. 如果查找不到目标节点则返回空
		
> put()方法源码

	public V put(K key, V value) {
	    return putVal(hash(key), key, value, false, true);
	}
	 
	final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
	               boolean evict) {
	    Node<K,V>[] tab; Node<K,V> p; int n, i;

	    // table是否为空或者length等于0，如果是则调用resize方法进行初始化
	    if ((tab = table) == null || (n = tab.length) == 0)
	        n = (tab = resize()).length;    

	    // 通过hash值计算索引位置，如果table表的该索引位置节点为空则新增一个节点
	    if ((p = tab[i = (n - 1) & hash]) == null)

			// 将新建索引位置的头节点赋值给计算得的索引
	        tab[i] = newNode(hash, key, value, null);
	    else {  

			// table表的该索引位置不为空
	        Node<K,V> e; K k;
	        if (p.hash == hash && // 判断p节点的hash值和key值是否和传入的hash值和key值相等
	            ((k = p.key) == key || (key != null && key.equals(k)))) 

				// 如果相等，则p节点即为要查找的目标节点，赋值给e
	            e = p;  

	        // 判断p节点是否为TreeNode，如果是则调用红黑树的putTreeVal方法查找目标节点
	        else if (p instanceof TreeNode) 
	            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
	        else {	
		
				// 这里代表p节点为普通链表节点，遍历此链表，binCount用于统计节点数
	            for (int binCount = 0; ; ++binCount) {  
	                if ((e = p.next) == null) { 

						// p.next为空代表不存在目标节点则新增一个节点插入链表尾部
	                    p.next = newNode(hash, key, value, null);

	                    // 计算节点是否超过8个，减一是因为循环是从p节点的下一个节点开始的
	                    if (binCount >= TREEIFY_THRESHOLD - 1)

							// 如果超过8个，调用treeifyBin方法将该链表转换为红黑树
	                        treeifyBin(tab, hash);
	                    break;
	                }
	                if (e.hash == hash && // e节点的hash值和key值都与传入的相等，则e即为目标节点，跳出循环
	                    ((k = e.key) == key || (key != null && key.equals(k)))) 
	                    break;

					// 将p指向下一个节点
	                p = e;  
	            }
	        }

	        // e不为空则代表根据传入的hash值和key值查找到了节点，将该节点的value覆盖，返回oldValue
	        if (e != null) { 
	            V oldValue = e.value;
	            if (!onlyIfAbsent || oldValue == null)
	                e.value = value;
	            afterNodeAccess(e); // 用于LinkedHashMap
	            return oldValue;
	        }
	    }
	    ++modCount;
	    if (++size > threshold) // 插入节点后超过阈值则进行扩容
	        resize();
	    afterNodeInsertion(evict);  // 用于LinkedHashMap
	    return null;
	}
	
	【说明】

		1. 校验table是否为空或者length等于0，如果是则调用resize方法进行初始化
		2. 通过hash值计算索引位置，将该索引位置的头节点赋值给p节点，如果该索引位置节点为空则使用传入的参数新增一个节点并放在该索引位置
		3. 判断p节点的key和hash值是否跟传入的相等，如果相等，则p节点即为要查找的目标节点，将p节点赋值给e节点
		4. 如果p节点不是目标节点，则判断p节点是否为TreeNode，如果是则调用红黑树的putTreeVal方法查找目标节点
		5. 走到这代表p节点为普通链表节点，则调用普通的链表方法进行查找，并定义变量binCount来统计该链表的节点数
		6. 如果p的next节点为空时，则代表找不到目标节点，则新增一个节点并插入链表尾部，并校验节点数是否超过8个，如果超过则调用treeifyBin方法将链表节点转为红黑树节点
		7. 如果遍历的e节点存在hash值和key值都与传入的相同，则e节点即为目标节点，跳出循环
		8. 如果e节点不为空，则代表目标节点存在，使用传入的value覆盖该节点的value，并返回oldValue
		9. 如果插入节点后节点数超过阈值，则调用resize方法进行扩容
	
	hash 算法，碰撞概率、扩容标准、链表变红黑树结构等。
	红黑树是特殊的平衡二叉查找树，平衡二叉查找树的特点：左节点 < 根节点 < 右节点

	【注意】
	重写equals后一定要重写 hashcode，以确保 哈希值的唯一性。
	如果不重写equals，那么比较的将是对象的引用是否指向同一块内存地址，重写之后目的是为了比较两个对象的value值是否相等。

	Java对于eqauls方法和hashCode方法是这样规定的：
		1. 如果两个对象相同（equals方法返回true），那么它们的hashCode值一定要相同；
		2. 如果两个对象的hashCode相同，它们并不一定相同。

	【总结】
	1. HashMap的底层是个Node数组（Node<K,V>[] table），在数组的具体索引位置，如果存在多个节点，则可能是以链表或红黑树的形式存在。Node<K,V> implements Map.Entry<K,V>
	
	2. 当同一个索引位置的节点在增加后超过8个【达到第9个】时，会触发链表节点（Node）转红黑树节点（TreeNode，间接继承Node），转成红黑树节点后，其实链表的结构还存在，通过next属性维持。
		链表节点转红黑树节点的具体方法为源码中的 treeifyBin(Node<K,V>[] tab, int hash)方法。

	3. 当同一个索引位置的节点在移除后达到第6个时，并且该索引位置的节点为红黑树节点，会触发红黑树节点转链表节点。
		红黑树节点转链表节点的具体方法为源码中的untreeify(HashMap<K,V> map)方法。
		
> linkedHashMap 类  

	linkedHashMap 继承 HashMap，linkedHashMap = HashMap + 双向链表。
	key 是有序的，按照插入顺序保存键；LinkedHashMap 也是一个HashMap，但是内部维持了一个双向链表，可以保持顺序。
	其中的属性：标志位accessOrder (值为true时，表示按照访问顺序迭代；值为false时，表示按照插入顺序迭代【默认】)。

	static class Entry<K,V> extends HashMap.Node<K,V> {
        Entry<K,V> before, after;
        Entry(int hash, K key, V value, Node<K,V> next) {
            super(hash, key, value, next);
        }
    }
	LinkedHashMap中的 Entry 增加了两个指针 before 和 after，它们分别用于维护双向链表。
	【注】next是用于维护 HashMap各个Entry的连接顺序【单链表】，before、after用于维护Entry插入的先后顺序的。

> ConcurrentHashMap 类

	JDK1.7采用分段的 数组 + 链表/红黑树 实现，线程安全。ConcurrentHashMap采用"分段锁"思想，每段就是一个 Segment 数组。
	Segment 继承了ReentrantLock，所以它就是一种可重入锁（ReentrantLock)。
	Segment类似于HashMap，一个Segment维护着一个Entry数组，并发环境下，对于同一个Segment的操作才需考虑线程同步，不同的Segment则不用考虑锁竞争。
	Segment是一种可重入锁ReentrantLock，在ConcurrentHashMap里扮演锁的角色，Entry则用于存储键值对数据。
	一个Segment里包含一个 Entry数组，每个Entry是一个链表结构的元素， 每个Segment守护者一个HashEntry数组里的元素,当对 Entry数组的数据进行修改时，必须首先获得它对应的Segment锁。

	通过把整个Map分为N个Segment，可以提供相同的线程安全，但是效率提升N倍，默认提升16倍。(读操作不加锁，由于 Entry的value变量是 volatile的，也能保证读取到最新的值。)
	ConcurrentHashMap默认将hash表分为16个Segment数组，一旦初始化完毕，Segment数组就不可以被扩容。

	数组默认容量为 16。
	扩容时大小总是2的幂次方。
	加载因子：0.75。Segment段内元素超过该段对应Entry数组长度的75%触发扩容，不会对整个Map进行扩容。
		
	有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁。

	JDK1.8的实现已经抛弃了Segment分段锁机制，利用 CAS + Synchronized 来保证并发更新的安全，底层采用 Node数组 + 链表 + 红黑树 的存储结构。
	而对于锁的粒度，调整为对每个数组元素加锁（Node）。
	ConcurrentHashMap 利用 红黑树 加强了并发能力。

	不允许key或value为 null值。

	重要的概念：
		table：默认为null，初始化发生在第一次插入操作，默认大小为16的数组。
			存放的数据类型：
				1. TreeBin 用于包装红黑树结构的结点类型 
				2. ForwardingNode 扩容时存放的结点类型，并发扩容的实现关键之一 
				3. Node 普通结点类型，表示链表头结点

		nextTable：默认为null，扩容时新生成的数组，其大小为原数组的两倍。

		sizeCtl ：默认为0，用来控制table的初始化和扩容操作
			>0 指定初始容量(非传入值，是2的幂次修正值)大小的两倍
			-1 代表table正在初始化
			-N 表示有N-1个线程正在进行扩容操作
			其余情况：
			1. 如果table未初始化，表示table需要初始化的大小。
			2. 如果table初始化完成，表示table的容量，默认是table大小的0.75倍，用这个公式算0.75（n - (n >>> 2)）。

		Node：保存key，value及key的hash值的数据结构。
			value和next都用 volatile 修饰，保证并发的可见性。

			static class Node<K,V> implements Map.Entry<K,V>

	CAS【Compare And Swap】算法
		unsafe.compareAndSwapInt(this, valueOffset, expect, update); 

		如果valueOffset位置包含的值与expect值相同，则更新valueOffset位置的值为update，并返回true，否则不更新，返回false。

	索引计算：
		int hash = spread(key.hashCode());
		int index = (tab.length - 1) & hash

	获取值
		tabAt(tab,index);		

	ConcurrentHashMap定义了三个原子操作【tabAt、casTableAt、setTabAt】，用于对指定位置的节点进行 获取、比较、设置 操作。
	正是这些原子操作保证了ConcurrentHashMap的线程安全。
	利用CAS进行无锁操作，可以大大提高性能，实现线程安全。
	
	    // 1. 获得在i位置上的Node节点最新的值
	    static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {
	        return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);
	    }
	
		// 2. 在i位置上插入Node节点（将c和tab[i]比较，相同则插入v）。 
	    static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i,
	                                        Node<K,V> c, Node<K,V> v) {
	        return U.compareAndSwapObject(tab, ((long)i << ASHIFT) + ABASE, c, v);
	    }
	
		// 3. 利用volatile方法设置节点位置的值
	    static final <K,V> void setTabAt(Node<K,V>[] tab, int i, Node<K,V> v) {
	        U.putObjectVolatile(tab, ((long)i << ASHIFT) + ABASE, v);
	    }


	初始化

		通过 compareAndSwapInt 初始化 sizeCtl的值
		sizeCtl 默认为 0，如果ConcurrentHashMap实例化时有传参数，sizeCtl会是一个2的幂次方的值。
		所以执行第一次put操作的线程会执行 Unsafe.compareAndSwapInt 方法修改sizeCtl为-1，有且只有一个线程能够修改成功，其它线程通过Thread.yield()让出CPU时间片等待table初始化完成。

	Put()方法

		ConcurrentHashMap中依然沿用HashMap的思想，有一个最重要的不同点就是ConcurrentHashMap 不允许key或value为 null值。
		如果这个位置是空的，那么直接放入，而且不需要加锁操作。
		不为空则使用 synchronized 加锁操作。

		由于通过 table[index] 不能保证线程每次都拿到table中的最新元素，
		所以需要通过 Unsafe.getObjectVolatile 直接获取指定内存的数据【tabAt(table, index)】，保证了每次拿到数据都是最新的。
		
		if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
                if (casTabAt(tab, i, null,
                             new Node<K,V>(hash, key, value, null)))
                    break;                   
            }
            else if ((fh = f.hash) == MOVED)
                tab = helpTransfer(tab, f);

		如果f【最新的Node节点值】为null，说明table中这个位置第一次插入元素，利用Unsafe.compareAndSwapObject方法插入Node节点。
		如果CAS成功，说明Node节点已经插入，随后addCount(1L, binCount)方法会检查当前容量是否需要进行扩容。
		如果CAS失败，说明有其它线程提前插入了节点，自旋重新尝试在这个位置插入节点。
		如果f的hash值为-1，说明当前f是ForwardingNode节点，意味有其它线程正在扩容，则一起进行扩容操作。
		其余情况把新的Node节点按链表或红黑树的方式插入到合适的位置，这个过程采用同步内置锁实现并发。
			else {
                V oldVal = null;
                synchronized (f) {
					...
				}

			在节点f上进行同步，节点插入之前，再次利用tabAt(tab, i) == f 判断，防止被其它线程修改。

			如果 f.hash >= 0，说明f是链表结构的头结点，遍历链表，如果找到对应的node节点，则修改value，否则在链表尾部加入节点。
			如果f是TreeBin类型节点，说明f是红黑树根节点，则在树结构上遍历元素，更新或增加节点。
			如果链表中节点数binCount >= TREEIFY_THRESHOLD(默认是8)，则把链表转化为红黑树结构。

		【注】
			hash值是大于0，表明是链表结点类型；
			hash值是小于0，表明是在迁移或红黑树结点类型；
		
	扩容
		当table容量不足的时候，即table的元素数量达到容量阈值sizeCtl，需要对table进行扩容。
		ConcurrentHashMap无锁多线程扩容，减少扩容时的时间消耗。
		整个扩容操作分为两个部分
		1. 构建一个nextTable，它的容量是原来的两倍，这个操作是单线程完成的。
		2. 使用transfer方法将原来table中的元素复制到nextTable中，这里允许多线程进行操作，所以需要 synchronized 加锁。

	get() 方法

		public V get(Object key) {
	        Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
	        int h = spread(key.hashCode());
	        if ((tab = table) != null && (n = tab.length) > 0 &&
	            (e = tabAt(tab, (n - 1) & h)) != null) {
				//直接返回
	            if ((eh = e.hash) == h) {
	                if ((ek = e.key) == key || (ek != null && key.equals(ek)))
	                    return e.val;
	            }

				// 若为红黑树，查找树
	            else if (eh < 0)	
	                return (p = e.find(h, key)) != null ? p.val : null;

				//链式遍历
	            while ((e = e.next) != null) {
	                if (e.hash == h &&
	                    ((ek = e.key) == key || (ek != null && key.equals(ek))))
	                    return e.val;
	            }
	        }
	        return null;
	    }

		1. 判断table是否为空，如果为空，直接返回null。
		2. 计算key的hash值，并获取指定table中指定位置的Node节点，通过遍历链表或则树结构找到对应的节点，返回value值。
		3. get()操作如果查询链表不用加锁，如果有 红黑树 结构的话 e.find() 方法内部实现需要获取锁。
	
> HashTable、ConcurrentHashMap

	线性安全：
	1. HashTable: HashTable的Synchronized是针对整张Hash表的，即每次锁住整张表让线程独占；
	2. ConcurrentHashMap ：采用 CAS+Synchronized 加锁，允许多个修改操作并发进行。

> TreeMap类

	HashMap通过 hashcode 对其内容进行快速查找，无序的；而TreeMap中所有的元素按 key 升序排序，有序的。
	在Map 中插入、删除和定位元素，HashMap 是最好的选择。
	但如果您要按自然顺序或自定义顺序遍历键，那么TreeMap会更好。
	使用HashMap要求添加的键类明确定义了hashCode()和 equals()的实现。
	TreeMap基于红黑树实现，没有调优选项，因为该树总处于平衡状态。

	需要实现 接口 Comparable<T> ，用于排序。

	LinkedHashMap 是根据元素增加或者访问的先后顺序进行排序，而 TreeMap 则根据元素的 Key 进行升序排序。

> HashMap和HashTable的区别：

	1. HashMap允许key和value为null，HashTable不允许。
	2. HashMap的默认初始容量为16，HashTable为11。
	3. HashMap的扩容为原来的2倍，HashTable的扩容为原来的2倍加1。
	4. HashMap是非线程安全的，HashTable是线程安全的。
	5. HashMap的hash值重新计算过，HashTable直接使用hashCode。
	6. HashMap去掉了HashTable中的contains方法。
	7. HashMap继承自AbstractMap类，HashTable继承自Dictionary类。
	
> Multimap

	多集合结构的map
	结构：Multimap<String, Object> 等效于 Map<K, Collection<V>>

	即 Multimap 的value 保存的是一个集合。

	比如：
	Multimap<String, Object> levelDeptMap = ArrayListMultimap.create();

	等效于
	Map<String, List<Object>>

	多集合嵌套时使用，简化操作。

<a name="4、Set接口"></a>
### 4、Set接口 ###

- Set是一种不包含重复的元素的Collection，且Set最多有一个null元素。Set 中的元素是无序的。
- 当使用 Set<POJO对象> 对POJO对象去重时，需要对 POJO对象 **重写 hashcode和equal方法**，告诉Set 使用POJO对象的哪个属性作为标识去重。

> HashSet 类

	此类实现 Set 接口，由哈希表（实际上是一个 HashMap 实例）支持。它不保证 set 的迭代顺序；
	特别是它不保证该顺序恒久不变。此类允许使用 null 元素。 
	操作 HashSet 的底层其实就是操作 HashMap 里面的键，使用的是HashMap 里面的方法。
	此实现不是同步的，Set s = Collections.synchronizedSet(new HashSet(...)); 封装该 set 的对象来执行同步操作。

> TreeSet 类

	操作 TreeSet 的底层其实就是操作 TreeMap 里面的键，使用的是TreeMap 里面的方法。

> LinkedHashSet

	LinkedHashSet继承自HashSet，LinkedHashSet 内部使用的是 LinkHashMap。
	使得 LinkedHashSet 中的元素顺序是可以保证的，也就是说遍历序和插入序是一致的。

	// HashSet中的构造函数
	HashSet(int initialCapacity, float loadFactor, boolean dummy) {
        map = new LinkedHashMap<>(initialCapacity, loadFactor);
    }

    LinkedHashSet通过继承HashSet，底层使用LinkedHashMap，以很简单明了的方式来实现了其自身的所有功能。

<a name="5、总结"></a>
### 5、总结 ###

	List、Set 继承了 Collection 接口，但 Map 没有继承。
	如果涉及到堆栈，队列等操作，应该考虑用List；对于需要快速插入，删除元素，应该使用LinkedList；如果需要快速随机访问元素，应该使用ArrayList。

	如果程序在单线程环境中，或者访问仅仅在一个线程中进行，考虑非同步的类，其效率较高；如果多个线程可能同时操作一个类，应该使用同步的类。

	要特别注意对哈希表的操作，作为key的对象要正确复写 equals和hashCode方法。

	使用Map时，查找、更新、删除、新增最好使用 HashMap或HashTable；
	对Map进行自然顺序或自定义键顺序遍历时，最好使用TreeMap;

	尽量返回接口而非实际的类型，如返回List而非ArrayList，这样如果以后需要将ArrayList换成LinkedList时，客户端代码不用改变。这就是针对抽象编程。

	
> List结构的集合类
	
		ArrayList类：异步的，线程并不安全，访问数组内的元素效率高，操作元素效率不高
		
		LinkedList类：异步的，线程并不安全，可以选择addFirst,addLast，操作元素效率高
		
		Vector类：同步的，线程安全性高
		
> map结构的集合类（键值结构）

	HashMap类：	异步执行，效率高，线程并不安全，键值可以放空值。
	
	Hashtable类：同步执行，效率受限，线程安全性高，不能放空值。
	
> 如何选用集合类？
	
	1. 要求线程安全，使用Vector、Hashtable
	2. 不要求线程安全，使用ArrayList,LinkedList,HashMap
	3. 要求key和value键值，则使用 HashMap,Hashtable
	4. 数据量很大，又要线程安全，则使用Vector

<a name="6、集合中的概念"></a>
### 6、集合中的概念 ###

> 数组：

	采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)；
	通过给定值进行查找，需要遍历数组，逐一比对给定关键字和数组元素，时间复杂度为O(n)，当然，对于有序数组，则可采用二分查找，插值查找，斐波那契查找等方式，可将查找复杂度提高为O(logn)；
	对于一般的插入删除操作，涉及到数组元素的移动，其平均复杂度也为O(n)

> 线性链表：

	对于链表的新增，删除等操作（在找到指定操作位置后），仅需处理结点间的引用即可，时间复杂度为O(1)，而查找操作需要遍历链表逐一进行比对，复杂度为O(n)。

> 哈希表：

	相比上述几种数据结构，在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)。
	可以把hash表看作是一个数组，通过哈希算法算出数组中的下标【hash值】，然后get()/put() 方法通过索引获取数据。

<a name="7、queue接口"></a>
### 7、queue接口 ###

> Queue
 
	基本上，一个队列就是一个先入先出（FIFO）的数据结构。
	Queue接口与List、Set同一级别，都是继承了Collection接口。

> BlockingQueue

	java.util.concurrent 中加入了 BlockingQueue 接口和五个阻塞队列类。
	它实质上就是一种带有一点扭曲的 FIFO 数据结构。
	不是立即从队列中添加或者删除元素，线程执行操作阻塞，直到有空间或者元素可用。

	五个队列所提供的各有不同：
		1. ArrayBlockingQueue ：		一个由数组支持的有界队列。
		2. LinkedBlockingQueue ：	一个由链接节点支持的可选有界队列。
		3. PriorityBlockingQueue ：	一个由优先级堆支持的无界优先级队列。
		4. DelayQueue ：				一个由优先级堆支持的、基于时间的调度队列。
		5. SynchronousQueue ：		一个利用 BlockingQueue 接口的简单聚集（rendezvous）机制。

> LinkedBlockingQueue

	在不指定时容量为Integer.MAX_VALUE，但是也可以选择指定其最大容量，它是基于链表的队列，此队列按 FIFO（先进先出）排序元素。
	LinkedBlockingQueue(int capacity)

> ArrayBlockingQueue

	在构造时需要指定容量， 并可以选择是否需要公平性，如果公平参数被设置true，等待时间最长的线程会优先得到处理（其实就是通过将ReentrantLock设置为true来 达到这种公平性的：即等待时间最长的线程会先操作）。
	通常，公平性会使你在性能上付出代价，只有在的确非常需要的时候再使用它。
	它是基于数组的阻塞循环队 列，此队列按 FIFO（先进先出）原则对元素进行排序。
	也可以在构造时初始化一个集合在队列中。
	ArrayBlockingQueue(int capacity, boolean fair, Collection<? extends E> c)

> PriorityBlockingQueue

	是一个带优先级的 队列，而不是先进先出队列。
	元素按优先级顺序被移除，该队列也没有上限，但是如果队列为空，那么取元素的操作take就会阻塞，所以它的检索操作take是受阻的。
	另外，往入该队列中的元素要具有比较能力。

> DelayQueue（基于PriorityQueue来实现的）
	
	是一个存放Delayed 元素的无界阻塞队列，只有在延迟期满时才能从中提取元素。
	该队列的头部是延迟期满后保存时间最长的 Delayed 元素。
	如果延迟都还没有期满，则队列没有头部，并且poll将返回null。
	当一个元素的 getDelay(TimeUnit.NANOSECONDS) 方法返回一个小于或等于零的值时，则出现期满，poll就以移除这个元素了。
	此队列不允许使用 null 元素。

		
![](images/collection1.png)

|队列的方法|说明|异常|
|:--|:--|:--|
|boolean add(E e);	|在队尾增加一个元索|如果队列已满，则抛出一个IIIegaISlabEepeplian异常|
|boolean offer(E e);|在队尾添加一个元素并返回true	|如果队列已满，则返回false|
|E remove();|移除并返回队列头部的元素	|如果队列为空，则抛出一个NoSuchElementException异常|
|E poll();	|移除并返问队列头部的元素	|如果队列为空，则返回null|
|E element();|返回队列头部的元素|如果队列为空，则抛出一个NoSuchElementException异常|
|E peek();|	返回队列头部的元素|如果队列为空，则返回null|


### 树 ###

> 二叉排序树（也称为二叉查找树）

	二叉排序树是最简单的查找树，特点：

		1. 是一棵二叉树;

		2. 左子树所有结点的值小于它的父结点的值，右子树所有结点的值大于它的父结点的值。

	1. 优点：

		二叉树是一种比顺序结构更加高效地查找目标元素的结构。
		它可以从第一个父节点开始跟目标元素值比较，如果相等则返回当前节点；
		如果目标元素值小于当前节点，则移动到左侧子节点进行比较；
		大于的情况则移动到右侧子节点进行比较，反复进行操作最终移动到目标元素节点位置。

	2. 缺点：

		在大部分情况下，我们设计索引时都会在表中提供一个自增整形的字段作为建立索引的列。
		在这种场景下使用二叉树的结构会导致我们的索引总是添加到右侧，在查找记录时跟没加索引的情况是一样的。
		即由于索引是有序的，添加索引到二叉树时会退化为链表。

> 平衡二叉树（又称AVL树）

	平衡二叉树是二叉排序树的基础上，对树的深度进行了限制，从而减少了查找比较的次数。

	特点：
	
	1. 是一棵二叉树;
	
	2. 左子树所有结点的值小于它的父结点的值，右子树所有结点的值大于它的父结点的值;
	
	3. 左子树与右子树的深度差在-1、0、1内，否则对子树进行旋转调整。

	对一棵相对平衡的有序二叉树，对其进行插入，查找，删除等操作，平均复杂度均为O(logn)。

> 红黑树

	1. 优点：

	红黑树也叫平衡二叉树，它不仅继承了二叉树的有点，而且解决了上面二叉树遇到的自增整形索引的问题。
	红黑树会自动对结构进行调整，始终保证左子节点 < 父节点 < 右子节点的规则，避免二叉树退化为链表。

	2. 缺点：

	在数据量大的时候，深度也很大。
	由于每个父节点只能存在两个子节点，如果我们有很多数据，那么树的深度依然会很大，可能就会超过十几二十层以上，加大了对IO的消耗，会花费很多时间查找。	


> Hash

	1. 优点：
	
	对数据进行Hash（散列）运算，主流的Hash算法有MD5、SHA256等等，然后将哈希结果作为文件指针可以从索引文件中获得数据的文件指针，再到数据文件中获取到数据。
	按照这样的设计，我们在查找where Col2 = 22的记录时只需要对22做哈希运算得到该索引所对应那行数据的文件指针，从而在MySQL的数据文件中定位到目标记录，查询效率非常高。
	时间复杂度为 o(1)
	
	2. 缺点：
	
	无法解决范围查询（Range）的场景，比如 select count(id) from sus_user where id >10；
	因此Hash这种索引结构只能针对字段名=目标值的场景使用，不适合模糊查询（like）的场景。

> B树（B-Tree）

	B树是多路平衡查找树，相对于平衡二叉树，对父结点的直接子结点个数，不再仅限于2。
	可以在树的深度不大量增加的前提下，保存更多的结点。
	只需要适当地增加每个树节点能存储的数据个数即可，但是数据个数也必须要设定一个合理的阈值，不然一个节点数据个数过多会产生多余的消耗。

	特点：

		若根结点不是叶子结点，则至少有两个子结点。
	
		父结点下的最左边子树所有结点的值均小于父结点最小值，最右边子树所有结点的值均大于父结点最大值，其余中间子树所有结点的值则介于指针的父结点两边的值;
	
		所有叶子结点都在同一层;

		B树的结构里每个节点包含了索引值和表记录的信息，我们可以按照Map集合这样理解：key=索引，value=表记录。

	优点：

		BTree的结构可以弥补红黑树的缺点，解决数据量过大时整棵树的深度过长的问题。
		相同数量的数据只需要更少的层，相同深度的树可以存储更多的数据，查找的效率自然会更高。

	缺点：

		在查询单条数据是非常快的。
		由于叶子节点没有链表直接相连，所以范围查找时需要跨层遍历。
		B-Tree结构每次都要从根节点查询一遍，效率会有所降低，因此在实际应用中采用的是另一种B-Tree的变种B+Tree（B+树）。

	B树通常在文件系统中使用。
		作用：
		1. 由于文件都是储存在硬盘上，需要加载到内存中，而一次性把所有的数据加载时磁盘I/O消耗很大，使用节点树可以支持分批次的加载到内存中，减少了磁盘I/O消耗；
		2. 多路平衡可以减少树的高度，从而减少了查找的时间，减少了磁盘I/O存取的消耗。

	【注意】所有结点均带有值。

> MySQL数据库它是如何读取索引数据的

	索引和表数据在不使用的时候是存储在文件中的，也就是磁盘。
	当我们执行查询操作时会DBMS（数据库管理系统）首先会先从内存中查找，如果找到直接使用，如果找不到则从磁盘文件中读取。
	操作系统储存数据的最小单位是页（page），一页假设是4K大小（由操作系统决定），对内存和磁盘读取数据是按一页的整数倍读取的。

	这里我们假设数据库一次IO操作就读取1页4K的数据，再假设一个大节点，内含多个小节点的索引和数据，其大小是10MB，那么我们要从磁盘中读取完整个大节点需要进行 10M / 4K = 2500次IO操作。
	这样就可以看出如果大节点数据总量越大，需要执行的IO操作越多，花费的时间也越长，因此为了提高性能，数据库会建议我们一个大节点只存储一页4K大小的数据，这里的数据包含了索引和表记录。
	另外我们还能计算出树的度Degree应该设置成多大才合理：

		Degree = 内存页大小（4K） / 单个索引值字节大小；
	
	进一步分析，索引值的大小相对于整条记录的大小是很小的，如果我们需要查找的数据刚好是在最后，那么前面遍历过的节点中存储的记录数据是不是对我们来说是没用的，它会占用比索引大得多的空间，导致我们一个大节点里能遍历的索引数量大大减少，需要向下继续遍历的几率就更大，就要花费更多时间查找。
	所以就需要对节点的存储数据进行优化，从而有了B+树。

> B+树（B+Tree）

	B+树是B树变体。

	相对于B-Tree，B+Tree做了哪些优化？

	1. B+Tree存储结构，只有叶子节点存储数据
	
		新的B+树结构没有在所有的节点里存储记录数据，而是只在最下层的叶子节点存储，上层的所有非叶子节点只存放索引信息。
		这样的结构可以让单个节点存放下更多索引值，增大度Degree的值，提高命中目标记录的几率。
	
		这种结构会在上层非叶子节点存储一部分冗余数据，但是这样的缺点都是可以容忍的，因为冗余的都是索引数据，不会对内存造成大的负担。

	2. 每个叶子节点都指向下一个叶子节点
		
		所有叶子结点都有一条指针链相连，即每个叶子节点都指向下一个叶子节点，构成了一条有序的链表【从小到大】，范围查找时就不需要跨层遍历。
		比如需要查找 id>4的记录，先找到id=4的节点，再通过叶子节点间的双向指针链表就可以查到小于4的节点。
	
	时间复杂度为 O(logN)
	
	mysql中存储引擎为Innodb的索引，采用的数据结构即是B+树。
	
	特点：
	
	1. 有m个子结点的父结点就有m个关键字;
	
	2. 所有叶子结点包含了所有关键字(值)，且构成由小到大的有序链表;
	
	3. 所有非叶子结点起索引作用，结点仅包含子树所有结点的最大值;
	
	4. 所有叶子结点都在同一层;
	
	【注意】叶子结点包含了所有的关键字（值），父结点只存放索引。

